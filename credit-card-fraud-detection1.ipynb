{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1><center><font size=\"6\">Credit Card Fraud Detection Predictive Models</font></center></h1>\n<h2><center><font size=\"5\">Dealing with Imbalanced Data</font></center></h2>\n\n\n<center><img src=\"https://images.unsplash.com/photo-1563013544-824ae1b704d3?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1050&q=80\" width=\"600\"></img></center>\n\n\n# <a id='0'>Content</a>\n\n- <a href='#1'>Introduction</a>  \n- <a href='#2'>Import Dependencies</a>  \n- <a href='#3'>Read the data</a>  \n- <a href='#4'>Check the data</a>  \n    - <a href='#41'>Glimpse the data</a>  \n    - <a href='#410'>Profile Report</a>\n    - <a href='#42'>Check missing data</a>\n    - <a href='#420'>Check Duplicates</a>\n    - <a href='#43'>Check data unbalance</a>\n- <a href='#5'>Data exploration</a>\n- <a href='#221'>Under-Sampling</a>\n- <a href='#6'>Predictive models</a>  \n    - <a href='#61'>RandomForrestClassifier</a> \n    - <a href='#62'>AdaBoostClassifier</a>\n    - <a href='#64'>XGBoost</a>\n    - <a href='#65'>Lazy Predict</a>\n- <a href='#7'>Conclusions</a>\n- <a href='#8'>References</a>\n","metadata":{}},{"cell_type":"markdown","source":"# <a id=\"1\">Introduction</a>  \n\nThe datasets contains transactions made by credit cards in **September 2013** by european cardholders. This dataset presents transactions that occurred in two days, where we have **492 frauds** out of **284,807 transactions**. The dataset is **highly unbalanced**, the **positive class (frauds)** account for **0.172%** of all transactions.  \n\nIt contains only numerical input variables which are the result of a **PCA transformation**.   \n\nDue to confidentiality issues, there are not provided the original features and more background information about the data.  \n\n* Features **V1**, **V2**, ... **V28** are the **principal components** obtained with **PCA**;  \n* The only features which have not been transformed with PCA are **Time** and **Amount**. Feature **Time** contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature **Amount** is the transaction Amount, this feature can be used for example-dependant cost-senstive learning.   \n* Feature **Class** is the response variable and it takes value **1** in case of fraud and **0** otherwise.  \n\n","metadata":{}},{"cell_type":"markdown","source":"# <a id=\"2\">Import Dependencies</a>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom pandas_profiling import profile_report\n\n%matplotlib inline\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom plotly import tools\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\n\nimport gc\nfrom datetime import datetime \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn import svm\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\nimport xgboost as xgb\n\nprint('Setup Completed')","metadata":{"execution":{"iopub.status.busy":"2023-10-02T18:56:04.831250Z","iopub.execute_input":"2023-10-02T18:56:04.831689Z","iopub.status.idle":"2023-10-02T18:56:04.844867Z","shell.execute_reply.started":"2023-10-02T18:56:04.831659Z","shell.execute_reply":"2023-10-02T18:56:04.843652Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.24.1.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}},{"name":"stdout","text":"Setup Completed\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# <a id='3'>Read the data</a> ","metadata":{}},{"cell_type":"code","source":"data_df = pd.read_csv('/kaggle/input/creditcardfraud/creditcard.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-02T18:56:06.295833Z","iopub.execute_input":"2023-10-02T18:56:06.296980Z","iopub.status.idle":"2023-10-02T18:56:10.804046Z","shell.execute_reply.started":"2023-10-02T18:56:06.296943Z","shell.execute_reply":"2023-10-02T18:56:10.802819Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# <a id='4'>Check the data</a> ","metadata":{}},{"cell_type":"code","source":"data_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T18:56:10.806201Z","iopub.execute_input":"2023-10-02T18:56:10.806884Z","iopub.status.idle":"2023-10-02T18:56:10.851253Z","shell.execute_reply.started":"2023-10-02T18:56:10.806843Z","shell.execute_reply":"2023-10-02T18:56:10.850134Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9  ...       V21       V22       V23       V24       V25  \\\n0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n\n        V26       V27       V28  Amount  Class  \n0 -0.189115  0.133558 -0.021053  149.62      0  \n1  0.125895 -0.008983  0.014724    2.69      0  \n2 -0.139097 -0.055353 -0.059752  378.66      0  \n3 -0.221929  0.062723  0.061458  123.50      0  \n4  0.502292  0.219422  0.215153   69.99      0  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data_df.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T18:56:10.852350Z","iopub.execute_input":"2023-10-02T18:56:10.852611Z","iopub.status.idle":"2023-10-02T18:56:10.899163Z","shell.execute_reply.started":"2023-10-02T18:56:10.852588Z","shell.execute_reply":"2023-10-02T18:56:10.897996Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 284807 entries, 0 to 284806\nData columns (total 31 columns):\n #   Column  Non-Null Count   Dtype  \n---  ------  --------------   -----  \n 0   Time    284807 non-null  float64\n 1   V1      284807 non-null  float64\n 2   V2      284807 non-null  float64\n 3   V3      284807 non-null  float64\n 4   V4      284807 non-null  float64\n 5   V5      284807 non-null  float64\n 6   V6      284807 non-null  float64\n 7   V7      284807 non-null  float64\n 8   V8      284807 non-null  float64\n 9   V9      284807 non-null  float64\n 10  V10     284807 non-null  float64\n 11  V11     284807 non-null  float64\n 12  V12     284807 non-null  float64\n 13  V13     284807 non-null  float64\n 14  V14     284807 non-null  float64\n 15  V15     284807 non-null  float64\n 16  V16     284807 non-null  float64\n 17  V17     284807 non-null  float64\n 18  V18     284807 non-null  float64\n 19  V19     284807 non-null  float64\n 20  V20     284807 non-null  float64\n 21  V21     284807 non-null  float64\n 22  V22     284807 non-null  float64\n 23  V23     284807 non-null  float64\n 24  V24     284807 non-null  float64\n 25  V25     284807 non-null  float64\n 26  V26     284807 non-null  float64\n 27  V27     284807 non-null  float64\n 28  V28     284807 non-null  float64\n 29  Amount  284807 non-null  float64\n 30  Class   284807 non-null  int64  \ndtypes: float64(30), int64(1)\nmemory usage: 67.4 MB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## <a id=\"41\">Glimpse the data</a>","metadata":{}},{"cell_type":"code","source":"print(\"Credit Card Fraud Detection data -  rows:\",data_df.shape[0],\" columns:\", data_df.shape[1])","metadata":{"execution":{"iopub.status.busy":"2023-10-02T18:56:10.902193Z","iopub.execute_input":"2023-10-02T18:56:10.903101Z","iopub.status.idle":"2023-10-02T18:56:10.908740Z","shell.execute_reply.started":"2023-10-02T18:56:10.903068Z","shell.execute_reply":"2023-10-02T18:56:10.907294Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Credit Card Fraud Detection data -  rows: 284807  columns: 31\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## <a id=\"410\">Profile Report</a>\n\nfunction generates a comprehensive report that includes various statistics, insights, and visualizations about the DataFrame. This report can be helpful in understanding the data, identifying missing values, exploring data distributions, detecting correlations, and more.","metadata":{}},{"cell_type":"code","source":"data_df.profile_report()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T18:56:40.369440Z","iopub.execute_input":"2023-10-02T18:56:40.369996Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa2c5def22d84dceb46a8bd7d2d56dbb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4abbecdc6d843ff89becea301259f3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cb30b0f85e44bb7bb01d40db6bcfdbf"}},"metadata":{}}]},{"cell_type":"markdown","source":"## <a id=\"42\">Check missing data</a>  \n\nLet's check if there is any missing data.","metadata":{}},{"cell_type":"code","source":"total = data_df.isnull().sum().sort_values(ascending = False)\npercent = (data_df.isnull().sum()/data_df.isnull().count()*100).sort_values(ascending = False)\npd.concat([total, percent], axis=1, keys=['Total', 'Percent']).transpose()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"there is no missing data","metadata":{}},{"cell_type":"markdown","source":"## <a id=\"420\">Check Duplicates</a>  \n\nLet's check if there are any Duplicates in our data","metadata":{}},{"cell_type":"code","source":"duplicated_values = data_df[data_df.duplicated()]\nprint(duplicated_values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df.drop_duplicates(inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"all done we droped the dupliccates","metadata":{}},{"cell_type":"markdown","source":"## <a id='43'>Check Unbalanced Data</a>","metadata":{}},{"cell_type":"code","source":"data_df['Class'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = data_df[\"Class\"].value_counts()\ndf = pd.DataFrame({'Class': temp.index,'values': temp.values})\n\ntrace = go.Bar(\n    x = df['Class'],y = df['values'],\n    name=\"Credit Card Fraud Class - data unbalance (Not fraud = 0, Fraud = 1)\",\n    marker=dict(color=\"Red\"),\n    text=df['values']\n)\ndata = [trace]\nlayout = dict(title = 'Credit Card Fraud Class - data unbalance (Not fraud = 0, Fraud = 1)',\n          xaxis = dict(title = 'Class', showticklabels=True), \n          yaxis = dict(title = 'Number of transactions'),\n          hovermode = 'closest',width=600\n         )\nfig = dict(data=data, layout=layout)\niplot(fig, filename='class')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Only 492 (or 0.172%) of transaction are fraudulent. That means the data is highly unbalanced with respect with target variable Class.","metadata":{}},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6))\ns = sns.boxplot(ax = ax1, x=\"Class\", y=\"Amount\", hue=\"Class\",data=data_df, palette=\"PRGn\",showfliers=True)\ns = sns.boxplot(ax = ax2, x=\"Class\", y=\"Amount\", hue=\"Class\",data=data_df, palette=\"PRGn\",showfliers=False)\nplt.show();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp = data_df[['Amount','Class']].copy()\nclass_0 = tmp.loc[tmp['Class'] == 0]['Amount']\nclass_1 = tmp.loc[tmp['Class'] == 1]['Amount']\nclass_0.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_1.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The real transaction have a larger mean value, larger Q1, smaller Q3 and Q4 and larger outliers; fraudulent transactions have a smaller Q1 and mean, larger Q4 and smaller outliers.","metadata":{}},{"cell_type":"markdown","source":"# <a id='221'>Under-Sampling</a>\n\nBuild a sample dataset containing similar distribution of normal transactions and Fraudulent Transactions\n\nNumber of Fraudulent Transactions --> 492","metadata":{}},{"cell_type":"code","source":"# Separete Data for Data Analysis\nlegit = data_df[data_df.Class == 0]\nfraudulent = data_df[data_df.Class == 1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check Shape of our Labels\nprint(legit.shape)\nprint(fraudulent.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Statistical measures of the data\nlegit.Amount.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fraudulent.Amount.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compare Both Transaction\ndata_df.groupby('Class').mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"legit_sample = legit.sample(n=492)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Concatenating two DataFrames\nnew_df = pd.concat([legit_sample, fraudulent], axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get Equal Features in Our two labels is our Goal in Under-Sampling Technique\nnew_df['Class'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <a id ='6'>Base line Modeling</a>","metadata":{}},{"cell_type":"markdown","source":"First we split our Data into two Classes","metadata":{}},{"cell_type":"code","source":"X = new_df.drop(columns='Class', axis=1)\nY = new_df['Class']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Split your dataset into a training set and a test set:","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <a id ='61'>RandomForest Classifier</a>","metadata":{}},{"cell_type":"markdown","source":"Let's run a model using the training set for training. Then, we will use the validation set for validation.\n\nWe will use as validation criterion GINI, which formula is GINI = 2 * (AUC) - 1, where AUC is the Receiver Operating Characteristic - Area Under Curve (ROC-AUC) [4]. Number of estimators is set to 100 and number of parallel jobs is set to 4.\n\nWe start by initializing the RandomForestClassifier.","metadata":{}},{"cell_type":"code","source":"# Define your parameter values\nRFC_METRIC = 'gini'  # or 'entropy' based on your choice\nNUM_ESTIMATORS = 100  # or any desired number\nNUM_JOBS = 4  # or any desired number\nRANDOM_STATE = 42  # or any desired value\n\n# Create the RandomForestClassifier with the defined parameter values\nclf_rfc = RandomForestClassifier(\n    n_jobs=NUM_JOBS,\n    random_state=RANDOM_STATE,\n    criterion=RFC_METRIC,\n    n_estimators=NUM_ESTIMATORS,\n    verbose=False\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf_rfc.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = clf_rfc.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Importance\n\nwe can classify if feature will be important to our model or no:","metadata":{}},{"cell_type":"code","source":"target = 'Class'\npredictors = ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\\\n       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19',\\\n       'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28',\\\n       'Amount']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp = pd.DataFrame({'Feature': predictors, 'Feature importance': clf_rfc.feature_importances_})\ntmp = tmp.sort_values(by='Feature importance',ascending=False)\nplt.figure(figsize = (7,4))\nplt.title('Features importance',fontsize=14)\ns = sns.barplot(x='Feature',y='Feature importance',data=tmp)\ns.set_xticklabels(s.get_xticklabels(),rotation=90)\nplt.show()  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Evaluation\n\nEvaluate the model's performance using appropriate metrics:","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy:.2f}\")\n\nconfusion = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\\n\", confusion)\n\nreport = classification_report(y_test, y_pred)\nprint(\"Classification Report:\\n\", report)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [None, 10, 20, 30],\n    # Add other hyperparameters to tune\n}\n\ngrid_search = GridSearchCV(estimator=clf_rfc, param_grid=param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\n\nbest_clf = grid_search.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <a id='64'>XGBoost Classifier</a>","metadata":{}},{"cell_type":"code","source":"clf_XGB = xgb.XGBClassifier(\n    learning_rate=0.1,  # Adjust as needed\n    n_estimators=100,   # Adjust as needed\n    max_depth=3,        # Adjust as needed\n    random_state=42     # Set a random state for reproducibility\n)\n\nclf_XGB.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = clf_XGB.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy:.2f}\")\n\nconfusion = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\\n\", confusion)\n\nreport = classification_report(y_test, y_pred)\nprint(\"Classification Report:\\n\", report)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [None, 10, 20, 30],\n    # Add other hyperparameters to tune\n}\n\ngrid_search = GridSearchCV(estimator=clf_XGB, param_grid=param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\n\nbest_clf = grid_search.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <a id='62'>AdaBoostClassifier </a>","metadata":{}},{"cell_type":"code","source":"# Create and train the AdaBoost classifier\nclf_ada = AdaBoostClassifier(\n    n_estimators=50,         # Adjust as needed\n    learning_rate=1.0,       # Adjust as needed\n    random_state=42           # Set a random state for reproducibility\n)\nclf_ada.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = clf_ada.predict(X_test)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy:.2f}\")\n\nconfusion = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\\n\", confusion)\n\nreport = classification_report(y_test, y_pred)\nprint(\"Classification Report:\\n\", report)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <a id='65'>Lazy Predict</a>\n\nPython library that provides a quick way to build and evaluate a wide range of machine learning models with minimal code. It's designed to help you get a sense of how different models perform on your dataset without the need for extensive manual configuration. It's particularly useful for initial exploratory data analysis and model selection.","metadata":{}},{"cell_type":"markdown","source":"install Lazy Predict","metadata":{}},{"cell_type":"code","source":"# !pip install lazypredict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from lazypredict.Supervised import LazyClassifier\n# fitting data in LazyRegressor because\n# here we are solving Regression use case.\nclf = LazyClassifier(verbose=0,\n                     ignore_warnings=False,\n                     custom_metric=None)\n  \n# fitting data in LazyClassifier\nmodels, predictions = clf.fit(X_train, X_test,\n                              y_train, y_test)\n# lets check which model did better\n# on Breast Cancer Dataset\nprint(models)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save Model","metadata":{}},{"cell_type":"code","source":"import joblib\n\njoblib.dump(clf_rfc, 'best_model.pkl')  # Save the best model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <a id='8'>Refrences</a>\n\n[1] Credit Card Fraud Detection Database, Anonymized credit card transactions labeled as fraudulent or genuine, https://www.kaggle.com/mlg-ulb/creditcardfraud\n\n[2] Principal Component Analysis, Wikipedia Page, https://en.wikipedia.org/wiki/Principal_component_analysis\n\n[3] RandomForrestClassifier, http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n\n[4] ROC-AUC characteristic, https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve\n\n[5] AdaBoostClassifier, http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n\n[6] CatBoostClassifier, https://tech.yandex.com/catboost/doc/dg/concepts/python-reference_catboostclassifier-docpage/\n\n[7] XGBoost Python API Reference, http://xgboost.readthedocs.io/en/latest/python/python_api.html\n\n[8] LightGBM Python implementation, https://github.com/Microsoft/LightGBM/tree/master/python-package\n\n[9] LightGBM algorithm, https://www.microsoft.com/en-us/research/wp-content/uploads/2017/11/lightgbm.pdf","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}